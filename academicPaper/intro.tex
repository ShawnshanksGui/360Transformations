\section{Introduction}
\label{sec:introduction}

\subsection{Context and Motivations}
\label{sec:context}

The popularity of navigable 360-degree video systems
has grown with the advent of both capturing systems
(including multi-camera with stitching systems) and interactive entertaining
systems (including head-mounted display devices).
However, the delivery of 360-degree video content, from servers
to the end-users,
is still a challenge.

\AD{Head-mounted devices (HMDs) display these videos in high resolution and frame rate, hence restricting the visible part to a viewer depending on the viewing angle, which is determined by the viewer's head direction. A viewing angle, measured horizontally or vertically from the head center and specific to a given HMD, determines how wide or long picture will be seen by a viewer. For example, with the viewing angle of 120 degrees a viewer will see only 1.3k of the video, assuming a 4k 360-degree video resolution\footnote{While the 4k FoV video resolution will require a 12k full spherical video size.}. The observable part of a 360-degree video at a given time, referred to as a \textbf{Field of View (FoV) video}, is defined by a horizontal, vertical viewing angle, and a resolution. A \textbf{FoV center} represents the center point of a FoV video.}{}
%two videos (one per eye), each of them with a high frame rate and a high resolution (typically $1080\times 1200$ for state-of-the-art devices).
%The combination of both videos
%form the \ac{FoV}, which is extracted
%from a wider spherical video with a resolution that is three to four times larger.

None of the current solutions for the delivery of 360-degree videos is entirely
satisfactory. Sending only \AD{FoV}{} videos is the least bandwidth-hungry implementation. However, it does
not enable fast
navigation within the 360-degree video: When the client moves the head, \AD{the FoV center changes, requiring a new FoV video to be immediately displayed. However, since a device has no knowledge about other parts of the spherical video, it has to notify the server about the changes and wait for reception of newly adjusted FoV video.}{}
%the device cannot immediately display any \ac{FoV} because it does not have information on the other
%parts of the full spherical video. The device has to notify the server and to wait
%for the reception of the newly adjusted \ac{FoV} videos.
Another delivery implementation is to send the full spherical video
and to let the device
extract the \ac{FoV} videos. This solution enables fast navigation but the bandwidth requirements are
significant.

We study in this paper a solution where the server offers multiple \emph{versions} of the same
360-degree video. Each version is characterized by a \emph{\ac{QEC}}, which is a given
position in the spherical video. Around the \ac{QEC}, the quality of the video is maximum,
while it is lower for video areas that are far from the \ac{QEC}.
The client downloads the video version
such that
the \ac{QEC} is close to the \AD{FoV center}.
The system is depicted in Figure~\ref{fig:deliverychain}.
This navigable 360-degree video delivery system has three advantages:
$(i)$ the bit-rate of the delivered video is lower than the original full-quality video.
$(ii)$ When the end-user does not move, the \ac{FoV} \AD{video}{} is extracted from the highest
quality spherical video.
And $(iii)$ when the end-user moves the head, the video does not stop. The device can
extract
a \AD{new}{} \ac{FoV} \AD{video}{} because it has the full spherical video. If the new \ac{FoV} \AD{center}{} is far from the
\ac{QEC} of the video version, the quality of the extracted video is lower but this
degradation is transient until the
device selects another video version with a closer \ac{QEC}.

\input{deliveryChain.tex}
%is characterized by an \emph{angle of vision}. It contains the full spherical
%video with an emphasis on the given angle of vision, \textit{i.e.},
%the part of the video that is in front of the angle of vision is at the highest quality and the video quality
%degrades for the other parts.

\subsection{Limitations of Previous Work}

The principle of delivering different qualities within a given navigable omnidirectional video is sketched
in a recent short paper by~\citet{ochi_live_2015}. Their proposal is based on the idea of video
tiling, which has been implemented for navigable panorama
video~\cite{sanchez_compressed_2015,wang_mixing_2014,gaddam_tiling_2015}:
The spherical video is mapped into an \emph{equirectangular} video, which
is cut into independent \emph{tiles} (typically $8\times 8$). The server offers several
video qualities for each tile. The client selects the quality of each tile according to
the \ac{FoV} of the end-user. This
solution has the same advantages as our proposal, but it neglects
the characteristics of 360-degree
videos. In an equirectangular video, the pixels
at the poles are over-sampled, which not only degrades the
performance of traditional video encoders~\cite{wojciechowski_h.264_2006,yu_framework_2015}, but also
makes equirectangular tiling less relevant. We consider instead geometric tiling on
other projections of spherical video.


The projection of spherical videos into a geometric layout generates
distortion on the resulting
full 2D video. Some layouts enable \ac{FoV} extraction without information
loss, typically on \emph{cube maps}~\cite{Ng2005} and
\emph{rhombic dodecahedron}~\cite{fu_rhombic_2009}. The previous work regarding
these
geometric layouts focuses on enabling efficient implementation of signal processing
functions~\cite{kazhdan_metric-aware_2010} and improving the video
encoding~\cite{tosic_low_2009}.
However, to the best of our knowledge, the
question of arranging various video qualities on the layout has not been studied so far.

Finally, a major content provider of 360-degree videos has recently released details about the
implementation of its delivery platform~\cite{facebook}. The depicted system is based
on the same idea as our proposal, where up to 30 versions of the same video are available depending on
\acp{QEC}. This implementation corroborates that, from an industrial perspective, the
extra-cost of
generating and storing multiple versions of the same video is worth the bandwidth
savings and the system usability. The authors project the spherical videos into a \emph{pyramid}
where the
base is the front
view and the peak is in the back. Yet, this projection under-samples pixels near the peak,
which
results in
information loss and distorted extraction of \ac{FoV} videos. \AD{Additionally, they projected the spherical videos into a \emph{cubemap}. However, unlike in our approach, they left the same full resolution of all faces, which limited the video size reduction.}{}

\subsection{Our Contributions}

%
%of spherical videos into various geometrical layouts. We propose
%several ways to arrange the video qualities, which leverage the structure of the
%different layouts.
We study the navigable 360-degree video delivery system with a
focus on the arrangement of video qualities within the projections of
spherical videos into geometric layouts. Our contribution is twofold:
\begin{itemize}
\item We introduce a tool (released on open source in a public
repository\footnote{url is hidden for blind
preservation.}), which enables the projection from a spherical video
into the most studied  geometric layout (and vice versa). The tool has two main
features: it allows
any arrangement of video quality depending on the layout, and it
extracts the
\ac{FoV} video from any point in the sphere.
\item We provide a comprehensive comparison of the different geometric arrangements of
video quality on 360-degree video. We address the main questions raised
by~\citet{facebook}: which layout provides the best trade-off
between bit-rate and
quality, how many video versions should be offered by the server, and what geometric
quality arrangement
enables the smoothest navigation.
\end{itemize}

In this short paper, we restrict our study to essentials, and we provide only our main findings based on a
sample of the results. \textit{Here are our findings...}




%%% Local Variables:
%%% mode: latex
%%% TeX-master: "paper"
%%% End:
