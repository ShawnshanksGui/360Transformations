\section{Conclusion}
\label{sec:conclusion}

We have introduced in this paper viewport-adaptive streaming for
navigable $360$-degree videos. Our system aims at offering both
interactive highs-quality service to \ac{HMD} users with low management
for \ac{VR} providers.
We studied the main system
settings of our framework, and validated its relevance.
We emphasize that, with current encoding techniques, the cube
map projection for two seconds segment length and six
\acp{QEC} offers the best performance. This
paper opens various research questions:
\begin{itemize}
  \item New adaptation algorithms should be studied for viewport navigation,
especially based on head movement prediction techniques using \emph{saliency maps} (probability of
presence), extracted from the feedback of
previous viewers~\cite{han2014spatial}. \citet{allthings} have recently made a first attempt in this
direction.

  \item New video encoding methods should be
developed to perform quality-differentiated encoding for
large-resolution videos. Especially, methods that allow for
intra-prediction and motion vector prediction across \emph{different} quality
areas. The recent work from~\citet{vishyArxiv} is a first step.

\item Specific studies for \emph{live} \ac{VR} streaming
and interactively-generated $360$-degree videos should be performed,
because the different representations can hardly be all
generated on the fly.
\end{itemize}
