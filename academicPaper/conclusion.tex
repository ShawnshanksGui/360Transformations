\section{Conclusion}
\label{sec:conclusion}

We have introduced in this paper viewport-adaptive streaming for
navigable 360-degree videos. \GS{Our proposal aims at offering both 
interactive highs-quality service to \ac{HMD} users with low management 
for \ac{VR} providers.
We have studied the main
settings of our proposal, and validated its relevance}.
%, which result in quality increase for a given bit-rate
%budget. 
\XC{We emphasize that, with current encoding techniques, the cube
map projection for \SI{2}{\second} segment length and \num{6}
\acp{QEC} offer the best performance}. This
paper opens various research questions: $(i)$ new
adaptation algorithms should be studied for viewport navigation,
especially based on head movement prediction techniques.
%\emph{saliency maps} \XC{(probability of
%presence)}{} for 360-degree videos\XC{, extracted from the feedback of
%previous viewers. More generally, head movement prediction techniques
%should be investigated.}{} 
$(ii)$ new video encoding methods should be
developed to perform quality-differentiated encoding for
large-resolution videos. \XC{Especially, methods that allow
intra-prediction and motion vector prediction across \emph{different} quality
area}.
%, and methods that takes into account the statistics of 360-degree
%videos.}{} 
%$(iii)$ new delivery mechanisms should be developed for the
%special case of ultra-wide-band wireless transmission at home.
\XC{$(iii)$ specific studies for \emph{live} \ac{VR} streaming
and interactively-generated 360-degree videos should be performed,
because the different representations can hardly be all
generated on the fly.}{}
