\section{Conclusion}
\label{sec:conclusion}

We have presented in this paper viewport-adaptive streaming for
navigable 360-degree videos. We have studied certain key parameter
settings, which result in quality increase for a given bit-rate
budget. \XC{We emphasize that, with current encoding methods, the cube
map projection for \SI{2}{\second} segment duration with
\numrange{5}{7} \acp{QEC} have the best quality increase.}{} This
paper highlights various exciting open questions, including: $(i)$ new
adaptation algorithms should be studied for viewport navigation,
especially based on \emph{saliency maps} \XC{(probability of
presence)}{} for 360-degree videos\XC{, extracted from the feedback of
previous viewers. More generally, head movement prediction techniques
should be investigated.}{} $(ii)$ new video encoding methods should be
developed to perform quality-differentiated encoding for
large-resolution videos. \XC{Especially, methods that allow
intra-prediction and motion vector prediction across different quality
area, and methods that takes into account the statistics of 360-degree
videos.}{} $(iii)$ new delivery mechanisms should be developed for the
special case of ultra-wide-band wireless transmission at home.
\XC{$(iv)$ specific studies for live streaming of 360-degree videos
and interactively generated 360-degree videos should be performed,
mainly because the different representations can hardly be all
generated beforehand.}{}
