\section{System architecture}


This section describes the system architecture of the proposed
navigable $360$-degree video delivery framework.

\parag{Server}The server takes as an input a $360$-degree video in
equirectangular format and transforms each frame into a desired
geometrical layout. Then, it creates $n$ different video
versions, each with a different \ac{QEC} and encoded in $k$ different
bit-rates (see Figure~\ref{fig:newdelivery}). The server
splits all such encoded videos into segments, which are classified in
$n\!\times\!k$ representations (based on their respective bit-rate and
\ac{QEC}), enabling clients to regularly switch from one
representation to another. The video quality around the
\ac{QEC} is the highest, while the remaining part is encoded at lower
quality.

\begin{figure}
   \centering
   \input{plots/newDelivery.tex}
   \caption{Viewort-adaptive streaming system: the server offers \num{6} representations (\num{3} \acp{QEC} at \num{2} bit-rates). The streaming session lasts for three segments. The client head moves from left to right, the available bandwidth varies. For each segment, the client requests a representation that matches both the \FoV{} and the network throughput.}
   \label{fig:newdelivery}
\end{figure}

\parag{Client}Over time the viewer moves the head and the
available bandwidth changes. Current \acp{HMD} record changes
in head orientation through rotation around three perpendicular axes,
denoted by \emph{pitch}, \emph{yaw}, and \emph{roll}.
Head movements modify the \FoV{} center, requiring a new viewport
to be displayed. State-of-the-art \acp{HMD} can perform the
extraction~\cite{fovhmds}. The client periodically sends a request
to the server for a new segment in the representation that
matches both the new \FoV{} center and the available throughput.

\parag{Adaptation algorithm}Similarly to \ac{DASH}, the client runs
an adaptation algorithm to select the video representation. It first
selects the \ac{QEC} of the video based on the \FoV{} center and
the available \acp{QEC}. This is an important addition to
the \ac{DASH} bit-rate adaptation logic, since the \ac{QEC} determines
the quality of the video that is delivered and displayed to the user.
After the \ac{QEC} selection, the client chooses the video
representation characterized by this \ac{QEC} and whose bit-rate fits
with the expected throughput for the next $x$ seconds (\textit{i.e.},
$x$ being the segment length). The server replies
with the requested video representation, from which the
client extracts the viewport, displaying it on the \ac{HMD}, as
shown in Figure~\ref{fig:newdelivery}.

Rate-adaptive streaming systems are based on the assumption that
the selected representation will match the network
conditions for the next $x$ seconds. Rate adaptation algorithms
are
developed~\cite{tian,probe_li_2014,miller,zou,liu} to reduce the mismatch between the
requested bit-rate and the throughput. In our proposal, the adaptation algorithm should also ensure
that the \FoV{} centers will be as close as possible to the chosen \ac{QEC} during
the $x$ next seconds.
In this paper, we implement
a simple algorithm for \ac{QEC} selection: we select the \ac{QEC} that
has the smallest orthodromic distance\footnote{The shortest distance
between two points on the surface of a sphere, measured along the
surface of the sphere. Its measure is proportional to the radius
of the sphere; we refer to ``distance unit'' to denote the
radius size.} to the \FoV{} center at the time the client runs
the adaptation algorithm. Similarly as for bit-rate adaptation, we
expect new viewport-adaptive algorithms to be developed in
the future to better predict the head movement and select the
\ac{QEC} accordingly.



\parag{Video segment length}A video segment length determines how
often requests can be sent to the server. It typically ranges from
\SIrange{1}{10}{\second}. Short segments enables quick
adaptation to head movement and bandwidth changes, but it increases
the overall number of segments and results in larger manifest files.
Shorter segments also increase the network overhead due to
frequent requests, as well as the network delay because of the round
trip time for establishing a TCP connection.
Longer segments improve the encoding efficiency and quality relative to
shorter ones, however they reduce the flexibility to adapt the video
stream to changes. We discuss segment length and head movement in
Section~\ref{subsec:segmentLength} based on a dataset.



\begin{lstlisting} [float, language=xml, frame=single, backgroundcolor=\color{white},lineskip={-1pt}, caption=Extensions of MPD file,captionpos=b, label=mpdChanges]
<?xml version="1.0"?>
<MPD>
  <Representation id="1" qec="90,60" bandwidth="9876" width="1920" height="1080" frameRate="30">
   <EssentialProperty schemeIdUri="urn:mpeg:dash:vrd:2017" value="0,0">
   <SegmentList timescale="1000" duration="2000">
   ...
  </Representation>
 </AdaptationSet>
</MPD>
</xml>
\end{lstlisting}

\parag{Extending the \ac{MPD} file} To implement the proposed
\FoV{}-adaptive video streaming, we extended a \ac{DASH} \ac{MPD}
file with new information, as illustrated in Listing~\ref{mpdChanges}.
Each representation contains the \texttt{coordinates} of its \ac{QEC}
in degrees, besides the parameters that are
already defined in the standard~\cite{iso_iec}.
Those coordinates are the two angles of the spherical coordinates of the \ac{QEC}, ranging respectively from \SIrange{0}{360} degrees and from \SIrange{-90}{90} degrees. All representations from the same adaptation set should have the same reference coordinate system.
The \texttt{@schemeIdUri} is used to indicate some extra information on the video such as the video source id and the projection type. The projection type is used by the client to determine if he knows how to extract viewports from this layout.
%It is also possible to define some \acp{RoI} to describe the geometry of the \ac{QEC} and the distribution of the quality.
%The \acp{RoI} are not mandatory in our architecture because the \ac{QEC} is often sufficient to decide which segment to select.
%If a \ac{RoI} is defined, we recommend using a \ac{RoI} defined on the sphere and not inside the projected video.
