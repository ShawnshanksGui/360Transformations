\section{System architecture}

\begin{figure}
   \centering
   \input{plots/newDelivery.tex}
   \caption{Viewort-adaptive streaming system: the server offers $n\times k$ representations ($n$ \acp{QEC} at $k$ bit-rates). The streaming session lasts for three segments from $s_1$ to $s_3$. The client moves her head from left to right, while her available bandwidth varies. For each segment, the client requests a representation that matches both the \ac{FoV} and the network throughput.}
   \label{fig:newdelivery}
\end{figure}

This section describes the system architecture of the proposed
navigable 360-degree video delivery framework.
% The principles of the navigable video delivery are similar as in
% adaptive bit-rate video systems such as \ac{DASH}\cite{Stockhammer11}.
% The server offers multiple versions of the same video
% and the client selects the most appropriate version according to some criteria. %These versions
% are cut into second-long segments such that the client can regularly switch from one
% version to another.

\parag{Server} The server takes as an input a 360-degree video in
equirectangular format and transforms each frame into a desired
geometrical layout. From there, it creates $n$ different video
versions, each with a different \ac{QEC} and encoded in $k$ different
bit-rates, as illustrated in Figure~\ref{fig:newdelivery}. The server
splits all such encoded videos into segments, which are classified in
$n\!\times\!k$ representations (based on their respective bit-rate and
\ac{QEC}), enabling the client to regularly switch from one
representation to another. The \GS{video quality}{} around the
\ac{QEC} is the highest, while the remaining part is encoded at lower
quality.

\begin{figure}
   \centering
   \input{plots/newDelivery.tex}
   \caption{Viewort-adaptive streaming system: the server offers $n\times k$ representations ($n$ \acp{QEC} at $k$ bit-rates). The streaming session lasts for three segments from $s_1$ to $s_3$. The client moves her head from left to right, while her available bandwidth varies. For each segment, the client requests a representation that matches both the \ac{FoV} and the network throughput.}
   \label{fig:newdelivery}
\end{figure}

\parag{Client}\XC{Over time the head of the user moves and the
available bandwidth changes. Current \ac{HMD} can only record changes
in head orientation through rotation around three perpendicular axes,
often denoted by \emph{pitch}, \emph{yaw}, and \emph{roll}.}{}.
\GS{Head movements}{} modify the FoV center, requiring a new viewport
to be displayed (\GS{state-of-the-art \acp{HMD} can perform the
extraction~\cite{fovhmds}}). The client periodically sends a request
to the server for a new video segment in the representation that
matches \GS{both}{} the new FoV center and the available throughput.

\parag{Adaptation algorithm} Similarly to \ac{DASH}, the client runs
an adaptation algorithm to select the video representation. It first
selects the \ac{QEC} of the video based on the \GS{FoV center}{} and
the available \acp{QEC} coordinates. This is an important addition to
the \ac{DASH} bit-rate adaptation logic, since the \ac{QEC} determines
the quality of the video that is delivered and displayed to the user.
After the \ac{QEC} selection, the client chooses the video
representation that contains this \ac{QEC} and whose bit-rate fits
with the expected throughput for the next $x$ seconds (\textit{i.e.},
$x$ being the segment \XC{duration}). It sends a request to the server
for the new segment in the chosen representation. The server replies
with the requested 360-degree video representation, from which the
client extracts the viewport, displaying it on the \ac{HMD}, as
illustrated in Figure~\ref{fig:newdelivery}.
%The center of the \ac{FoV} is a point on the
%sphere, while the size of the FoV depends on the device (typically
%around 100$^\circ$ in state-of-the-art devices).

%\parag{Adaptive video streaming}
The adaptive video streaming system is based on the assumption that
the selected representation will match the client/network
\XC{conditions}{} for the next $t$ seconds. The requested bit-rate
needs to match the current throughput for the duration of the segment,
otherwise the user might experience video stalls, interruptions, and
delays. Many bitr-ate adaptation algorithms have been recently
developed~\cite{tian,probe_li_2014,miller,zou,liu}. In our approach,
we additionally assume that the chosen \ac{QEC} will be close to the
\ac{FoV} center for the next $t$ seconds. In this paper, we implement
a simple algorithm for \ac{QEC} selection: we select the \ac{QEC} that
has the smallest orthodromic distance\footnote{The shortest distance
between two points on the surface of a sphere, measured along the
surface of the sphere. \XC{Its measure is proportional to the radius
of the sphere; we refer to "distance unit" in the text to denote the
size of the radius.}{}} to the FoV center at the time the client runs
the adaptation algorithm. Similarly as for bit-rate adaptation, we
expect new 360-degree video adaptation algorithms to be developed in
the future to better predict the head movement \GS{and select the
\ac{QEC} accordingly}.

% and adjust the video segment length and
%qualities in 360-degree video accordingly.
%This head movement prediction will be based on the user's previous head movements and the video content type. If the content is static, the user will not move his/her head so much compared to when watching an action move.


\parag{Video segment length} A video segment length determines how
often requests can be sent to the server. It typically ranges from
\SIrange{1}{10}{\second} per segment. Short segments enables quick
adaptation to head movement and bandwidth changes, but it increases
the overall number of segments and results in larger manifest files.
Shorter segments also increase the network overhead by allowing for
frequent requests, as well as the network delay because of the round
trip time that is needed to establish a TCP connection.
%\footnote{In case of non-persistent HTTP connection TCP connection is established with the server after each request.} and request a segment (which can both take significant time in case of short segment sizes).
Longer segments improve the encoding efficiency and quality relative to
shorter ones, however they reduce the flexibility to adapt the video
stream to changes. We discuss segment length and head movement in
Section~\ref{subsec:segmentLength} based on a dataset.

% However, if the user's head moves during this time, the consequences for the user will be even worse than with the adaptive streaming, including the degraded video quality. A new \ac{FoV} video will be extrapolated from the existing video version stored on the client. The longer the time between the requests, the longer the potential distance from the old to the new \ac{FoV} center (i.e., \ac{FoV} center distance), and the larger the quality degradation of the extracted \ac{FoV} video. In order to improve quality of the displayed video in future, we plan to predict which \ac{QEC} will be close to \ac{FoV} center for the entire segment duration, showing this area in full quality.

%The specifics of 360-degree video delivery are that only a portion of the delivered 360-degree video is displayed on the user's HMD (i.e., where the user looks at). Therefore, only this part of the video (around the \ac{QEC}) should be given in full quality, while the quality of the remaining video can be adjusted to the user's head movements and the viewing probability. A video that is mapped to a given geometric layout is split into viewing faces, each of which corresponds to specific viewing direction and can be assigned a different quality.

\parag{Extending the \ac{MPD} file} To implement the proposed
\ac{FoV}-adaptive video streaming, we extended a \ac{DASH} \ac{MPD}
file with new information, as illustrated in Listing~\ref{mpdChanges}.
Each representation contains the \texttt{\ac{QEC}}
\texttt{coordinates} in degrees, besides the parameters that are
already defined in the standard~\cite{iso_iec}. Similarly, an
adaptation set is extended with \texttt{geometrical} \texttt{layout}
and \texttt{quality} \texttt{arrangement} attributes, for video
encoder to know how to encode the video. The geometrical layout is one
of the projection types (equirectangular, cube map, pyramid or
dodecahadron), while the quality arrangement takes a string value
specifying the qualities of the different faces. In this example, we
propose to represent the number of layout faces encoded in the
high/medium/low qualities. The proposed changes are added as new
attributes of the \texttt{Representation} and \texttt{AdaptationSet}
tags. With such extensions, we maintain conformance with the standard,
ensuring interworking with legacy \ac{DASH} clients that can simply
ignore these newly introduced attributes.

\begin{minipage}{\linewidth}
\begin {lstlisting} [language=xml, frame=single, backgroundcolor=\color{white},lineskip={-1pt}, caption=Extensions of MPD file, label=mpdChanges]
<?xml version="1.0"?>
   <MPD>
    ...
        <AdaptationSet geometricLayout="cubeMap" qualityArrangement="1/0/4">
            <Representation id="1" qec="90,60" bandwidth="9876" width="1920" height="1080" frameRate="30">
                <SegmentList timescale="1000" duration="2000">
                ...
            </Representation>
        </AdaptationSet>
    </MPD>
</xml>
\end{lstlisting}
\end{minipage}
