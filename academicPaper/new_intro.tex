\section{Introduction}
\label{sec:introduction}

%\subsection{Context and Motivations}
%\label{sec:context}

The popularity of navigable 360-degree video systems
has grown with the advent of both capturing systems
(including multi-camera with stitching systems) and interactive displaying
systems (including head-mounted devices).
However, the delivery of 360-degree video content, from servers
to the end-users,
is still a challenge.

Let us provide some numbers to illustrate the challenge.
A 360-degree video is either a real scene captured in every direction
to form one global video, or in the case of gaming, a virtual scene from which the
game engine pre-computes views in all directions around the main player.
In the same manner that a human
views the real world from a given perspective, an \ac{HMD} displays only a portion
of the 360-degree video. The displayed scene is called the \textit{\ac{FoV}}. It is commonly
defined by
a device-specific viewing angle (typically 120 degrees), which delimits horizontally or
vertically the scene from the head direction center, called \ac{FoV} center. To get a good
immersion, the pixel
resolution of
the displayed \ac{FoV} should be high, typically 4k ($3840\times2160$). It means that
the resolution of the full 360-degree video should be at least 12k ($11520\times6480$).
Furthermore, to prevent the so-called \emph{simulator sickness}~\cite{moss2011characteristics}, the \ac{HMD}
vendors recommend to make the system react to head movement as fast as the \ac{HMD}
refresh rate.\footnote{\url{https://developer.oculus.com/documentation/intro-vr/latest/concepts/bp_intro/}} Given that the refresh rate of
state-of-the-art \acp{HMD} is \SI{90}{Hz}, the video frame rate should thus be high,
typically around 100\,\acp{fps}.
Overall, high-quality 360-degree videos combine both large resolution (up to 12k) and high
frame rate (up to 100\,\acp{fps}), which makes them impossible to stream on any
state-of-the-art access network technology. To compare, the bit-rate of 8k videos
at 60\,\acp{fps} encoded in \ac{HEVC} is around \SI{100}{Mbps}~\cite{7398367}.

As we will see in Section~\ref{sec:relatedwork}, none of the current solutions
for the delivery of 360-degree videos is entirely
satisfactory. Sending only FoV videos does
not enable fast
navigation within the 360-degree video: When the client moves the head, the FoV
center changes, requiring a new FoV video to be immediately displayed. However, since
the device has no knowledge about other parts of the spherical video, it has to notify
the server about the viewer head's movement and wait for reception of the newly
adjusted FoV video.
Another delivery implementation is to send the full spherical video
and to let the device
extract the \ac{FoV} videos. This solution enables fast navigation but the bandwidth
requirements are
significant.

We propose in this paper a solution where, following the same principles as in
rate-adaptive streaming technologies, the server offers multiple \emph{versions} of the same
360-degree video. But instead of offering versions that only differ by
their bit-rate and their resolution, the server offers here versions that differ by
having a better quality in a given region of the video.
Our proposal is a \emph{region-adaptive streaming system} and is depicted in
Figure~\ref{fig:deliverychain}.
Each version is characterized by a \emph{\ac{QEC}}, which is a given
position in the spherical video. Around the \ac{QEC}, the quality of the video is maximum,
while it is lower for video areas that are far from the \ac{QEC}. Similarly as
in \ac{DASH}, the video is cut into segments and the client periodically selects
the video version with respect to an adaptation logic algorithm. Here, the client downloads
the video version
such that, not only the bit-rate fits with their bandwidth, but also
the \ac{QEC} is the closest to their \AD{FoV center}.

\input{deliveryChain.tex}

This region-adaptive 360-degree streaming system has three advantages:
$(i)$ the bit-rate of the delivered video is lower than the original full-quality video.
$(ii)$ When the end-user does not move, the \ac{FoV} video is extracted from the highest
quality spherical video.
And $(iii)$ when the end-user moves the head, the video does not stop. The device can
always extract
a new \ac{FoV} video because it has the full spherical video. If the
new \ac{FoV} center is far from the
\ac{QEC} of the video version, the quality of the extracted video is lower but this
degradation is transient until the
device selects another video version with a closer \ac{QEC}.

In this paper, we introduce region-adaptive streaming systems for navigable 360-degree
videos and we discuss the key design points of such system. We address
the choice of the projection from a spherical video into a geometric two-dimensional layout
with a focus on the impact of this projection into the quality of the video encoding. We evaluate
several video quality arrangement into the geometric layouts and we show that the
cube map layout offers the best performance regarding the quality of the extracted
\ac{FoV}.
Furthermore, based on a dataset of
real users navigating in 360-degree videos, we study the length of the video segments
for region-adaptive streaming system. We show that head movements are significant
in short period, so the video segments have to be short enough to enable
frequent region switches.

Finally, we introduce a tool (released on open source in a public
repository\footnote{url is hidden for blind
preservation.}), which create video versions for region-adaptive 360-degree videos.
The tool is highly configurable: from a given 360-degree video, it allows
any arrangement of video quality depending on any geometric layout, and it
extracts the
\ac{FoV} video from any point in the sphere. This tool thus provides the
main software modules for the implementation of region-adaptive streaming
for navigable 360-degree videos.

%is characterized by an \emph{angle of vision}. It contains the full spherical
%video with an emphasis on the given angle of vision, \textit{i.e.},
%the part of the video that is in front of the angle of vision is at the highest quality and the video quality
%degrades for the other parts.

\section{Related Work}
\label{sec:relatedwork}

The principle of delivering different qualities within a given navigable omnidirectional video is sketched
in a recent short paper by~\citet{ochi_live_2015}. Their proposal is based on the idea of video
tiling, which has been implemented for navigable panorama
video~\cite{sanchez_compressed_2015,wang_mixing_2014,gaddam_tiling_2015}:
The spherical video is mapped into an \emph{equirectangular} video, which
is cut into independent \emph{tiles} (typically $8\times 8$). The server offers several
video qualities for each tile. The client selects the quality of each tile according to
the \ac{FoV} of the end-user. This
solution has the same advantages as our proposal, but it neglects
the characteristics of 360-degree
videos. In an equirectangular video, the pixels
at the poles are over-sampled (a pixel on the sphere is projected to a pair of pixels in the equirectangular image), which not only degrades the
performance of traditional video encoders~\cite{wojciechowski_h.264_2006,yu_framework_2015}, but also
makes equirectangular tiling less relevant. We consider instead geometric tiling on
other projections of spherical video.

The projection of a sphere into a plane (known as mapping) has been extensively studied
for centuries. In this paper, we consider four projections that are the most natural
candidates for 360-degree video delivery. These layouts are depicted in Figure~\ref{fig:mapping}. The advantages and shortcomings of every projection have been studied in the literature. From
the images that are
projected on an equirectangular, a cube map, and a rhombic dodecahedron, it is possible
to generate a \ac{FoV}
for any position and angle in the sphere without an information loss ~\cite{Ng2005} ~\cite{fu_rhombic_2009}. On the
contrary, a pyramid layout projects some pairs of pixels on a sphere (i.e., those that are in the back of the view face) into a single pixel in the projected image by interpolating their color values, causing distortions and information loss in the generated FoV. Hence, the back view is the least probable head orientation of the video viewer, therefore the impact on the user experience is minimal.

Arranging video qualities of the layout faces according to their likelihood of viewing (e.g., encoding the front face in full resolution and the back face in the low resolution) is an important factor of optimizing user experience. However, to the best of our knowledge, it has not been studied yet.
The previous work regarding projection of spherical videos into different
geometric layouts focuses on enabling efficient implementation of signal processing
functions~\cite{kazhdan_metric-aware_2010} and improving the video
encoding~\cite{tosic_low_2009}.

\begin{figure}[t]
\centering
\begin{tikzpicture}
\def\sizeSphere{20}%pt
\def\ecartY{-1.2}%cm
\def\ecartX{6}

% da sphere
\pic [local bounding box=spher]  at (0,0) {spherical=15};

% recantagular
\pic [local bounding box=equi] at (-3,\ecartY) {equirectangular={\sizeSphere}{-1}{0}};

% cupe map
\pic [local bounding box=cubemap] at (-1,\ecartY) {cubemap=\sizeSphere};

% pyramid
\pic [local bounding box=pyra] at (1,\ecartY) {pyramid=\sizeSphere};

% rhombic
%\pgfdeclareimage[width=36 pt]{dodecahedron}{RhombicDodecahedron.png}
%\node at (3,\ecartY) (dodec)
%    {\pgfbox[center,center]{\pgfuseimage{dodecahedron}}};

\def\unitused{0.22}

\pic [local bounding box=dodeca] at (3,0.88*\ecartY) {dodecahedron=\unitused};

% links
\draw[-latex] (spher.180) -| (equi);
\draw[-latex] (spher.200) -| (cubemap);
\draw[-latex] (spher.340) -| (pyra);
\draw[-latex] (spher) -| (dodeca);

\node[font=\scriptsize,anchor=north] at (equi.south) {equirectangular};
\node[font=\scriptsize,anchor=north] at (cubemap.south) {cube map};
\node[font=\scriptsize,anchor=north] at (pyra.south) {pyramid};
\node[font=\scriptsize,anchor=north] at (dodeca.south) {\vphantom{y}dodecahedron};

\end{tikzpicture}
\caption{Projections into four geometric layouts}\label{fig:mapping}
\end{figure}





%The projection of spherical videos into a geometric layout generates
%distortion on the resulting
%full 2D video. Some layouts enable \ac{FoV} extraction without information
%loss, typically on \emph{cube maps}~\cite{Ng2005} and
%\emph{rhombic dodecahedron}~\cite{fu_rhombic_2009}. 

%However, to the best of our knowledge, the
%question of arranging various video qualities on the layout has not been studied so far.

Finally, a major content provider of 360-degree videos has recently released details about the
implementation of its delivery platform~\cite{facebook}. The depicted system is based
on the same idea as our proposal, where up to 30 versions of the same video are available depending on
\acp{QEC}. This implementation corroborates that, from an industrial perspective, the
extra-cost of
generating and storing multiple versions of the same video is worth the bandwidth
savings and the system usability. The authors project the spherical videos into a \emph{pyramid}
where the
base is the front
view and the peak is in the back. Yet, this projection under-samples pixels near the peak,
which
results in
information loss and distorted extraction of \ac{FoV} videos. \AD{Additionally, they projected spherical videos into a \emph{cubemap}. However, unlike in our approach, they left the same full resolution of all faces, which limited the video size reduction.}{}

%\subsection{Our Contributions}
%
%%
%%of spherical videos into various geometrical layouts. We propose
%%several ways to arrange the video qualities, which leverage the structure of the
%%different layouts.
%We study the navigable 360-degree video delivery system with a
%focus on the arrangement of video qualities within the projections of
%spherical videos into geometric layouts. Our contribution is twofold:
%\begin{itemize}
%\item
%\item We provide a comprehensive comparison of the different geometric arrangements of
%video quality on 360-degree video. We address the main questions raised
%by~\citet{facebook}: which layout provides the best trade-off
%between bit-rate and
%quality, how many video versions should be offered by the server, and what geometric
%quality arrangement
%enables the smoothest navigation.
%\end{itemize}
%
%In this short paper, we restrict our study to essentials, and we provide only our main findings based on a
%sample of the results. \textit{Here are our findings...}
%
%


%%% Local Variables:
%%% mode: latex
%%% TeX-master: "paper"
%%% End:
