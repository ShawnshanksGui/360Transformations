\section{Introduction}
\label{sec:introduction}

%\subsection{Context and Motivations}
%\label{sec:context}

The popularity of navigable 360-degree video systems
has grown with the advent of both capturing systems
(including multi-camera with stitching systems) and interactive displaying
systems (including head-mounted devices).
However, the delivery of 360-degree video content, from servers
to the end-users,
is still a challenge.

Let us provide some numbers to illustrate the challenge.
A 360-degree video is either a real scene captured in every direction
to form one global video, or in the case of gaming, a virtual scene from which the
game engine pre-computes views in all directions around the main player.
In the same manner that a human
views the real world from a given perspective, an \ac{HMD} displays only a portion
of the 360-degree video. The displayed scene is called the \textit{\ac{FoV}}. It is commonly
defined by 
a device-specific viewing angle (typically 120 degrees), which delimits horizontally or 
vertically the scene from the head direction center, called \ac{FoV} center. To get a good 
immersion, the pixel 
resolution of
the displayed \ac{FoV} should be high, typically 4k ($3840\,\times\,2160$). It means that
the resolution of the full 360-degree video should be at least 12k ($11520\,\times\,6480$). 
Furthermore, to prevent the so-called \emph{simulator sickness}~\cite{moss2011characteristics}, the \ac{HMD} 
vendors recommend to make the system react to head movement as fast as the \ac{HMD}
refresh rate.\footnote{\url{https://developer.oculus.com/documentation/intro-vr/latest/concepts/bp_intro/}} Given that the refresh rate of 
state-of-the-art \acp{HMD} is \SI{90}{Hz}, the video frame rate should thus be high,
typically around 100\,\acp{fps}.
Overall, high-quality 360-degree videos combine both large resolution (up to 12k) and high
frame rate (up to 100\,\acp{fps}), which makes them impossible to stream on any
state-of-the-art access network technology. To compare, the bit-rate of 8k videos 
at 60\,\acp{fps} encoded in \ac{HEVC} is around \SI{100}{Mbps}~\cite{7398367}.



None of the current solutions for the delivery of 360-degree videos is entirely
satisfactory. Sending only \AD{FoV}{} videos is the least bandwidth-hungry implementation. However, it does
not enable fast
navigation within the 360-degree video: When the client moves the head, \AD{the FoV center changes, requiring a new FoV video to be immediately displayed. However, since a device has no knowledge about other parts of the spherical video, it has to notify the server about the viewer head's movement and wait for reception of newly adjusted FoV video.}{}
%the device cannot immediately display any \ac{FoV} because it does not have information on the other
%parts of the full spherical video. The device has to notify the server and to wait
%for the reception of the newly adjusted \ac{FoV} videos.
Another delivery implementation is to send the full spherical video
and to let the device
extract the \ac{FoV} videos. This solution enables fast navigation but the bandwidth requirements are
significant.

We study in this paper a solution where the server offers multiple \emph{versions} of the same
360-degree video. Each version is characterized by a \emph{\ac{QEC}}, which is a given
position in the spherical video. Around the \ac{QEC}, the quality of the video is maximum,
while it is lower for video areas that are far from the \ac{QEC}.
The client downloads the video version
such that
the \ac{QEC} is close to the \AD{FoV center}.
The system is depicted in Figure~\ref{fig:deliverychain}.
This navigable 360-degree video delivery system has three advantages:
$(i)$ the bit-rate of the delivered video is lower than the original full-quality video.
$(ii)$ When the end-user does not move, the \ac{FoV} \AD{video}{} is extracted from the highest
quality spherical video.
And $(iii)$ when the end-user moves the head, the video does not stop. The device can
extract
a \AD{new}{} \ac{FoV} \AD{video}{} because it has the full spherical video. If the new \ac{FoV} \AD{center}{} is far from the
\ac{QEC} of the video version, the quality of the extracted video is lower but this
degradation is transient until the
device selects another video version with a closer \ac{QEC}.

\input{deliveryChain.tex}
%is characterized by an \emph{angle of vision}. It contains the full spherical
%video with an emphasis on the given angle of vision, \textit{i.e.},
%the part of the video that is in front of the angle of vision is at the highest quality and the video quality
%degrades for the other parts.

\subsection{Limitations of Previous Work}

The principle of delivering different qualities within a given navigable omnidirectional video is sketched
in a recent short paper by~\citet{ochi_live_2015}. Their proposal is based on the idea of video
tiling, which has been implemented for navigable panorama
video~\cite{sanchez_compressed_2015,wang_mixing_2014,gaddam_tiling_2015}:
The spherical video is mapped into an \emph{equirectangular} video, which
is cut into independent \emph{tiles} (typically $8\times 8$). The server offers several
video qualities for each tile. The client selects the quality of each tile according to
the \ac{FoV} of the end-user. This
solution has the same advantages as our proposal, but it neglects
the characteristics of 360-degree
videos. In an equirectangular video, the pixels
at the poles are over-sampled, which not only degrades the
performance of traditional video encoders~\cite{wojciechowski_h.264_2006,yu_framework_2015}, but also
makes equirectangular tiling less relevant. We consider instead geometric tiling on
other projections of spherical video.


The projection of spherical videos into a geometric layout generates
distortion on the resulting
full 2D video. Some layouts enable \ac{FoV} extraction without information
loss, typically on \emph{cube maps}~\cite{Ng2005} and
\emph{rhombic dodecahedron}~\cite{fu_rhombic_2009}. The previous work regarding
these
geometric layouts focuses on enabling efficient implementation of signal processing
functions~\cite{kazhdan_metric-aware_2010} and improving the video
encoding~\cite{tosic_low_2009}.
However, to the best of our knowledge, the
question of arranging various video qualities on the layout has not been studied so far.

Finally, a major content provider of 360-degree videos has recently released details about the
implementation of its delivery platform~\cite{facebook}. The depicted system is based
on the same idea as our proposal, where up to 30 versions of the same video are available depending on
\acp{QEC}. This implementation corroborates that, from an industrial perspective, the
extra-cost of
generating and storing multiple versions of the same video is worth the bandwidth
savings and the system usability. The authors project the spherical videos into a \emph{pyramid}
where the
base is the front
view and the peak is in the back. Yet, this projection under-samples pixels near the peak,
which
results in
information loss and distorted extraction of \ac{FoV} videos. \AD{Additionally, they projected the spherical videos into a \emph{cubemap}. However, unlike in our approach, they left the same full resolution of all faces, which limited the video size reduction.}{}

\subsection{Our Contributions}

%
%of spherical videos into various geometrical layouts. We propose
%several ways to arrange the video qualities, which leverage the structure of the
%different layouts.
We study the navigable 360-degree video delivery system with a
focus on the arrangement of video qualities within the projections of
spherical videos into geometric layouts. Our contribution is twofold:
\begin{itemize}
\item We introduce a tool (released on open source in a public
repository\footnote{url is hidden for blind
preservation.}), which enables the projection from a spherical video
into the most studied  geometric layout (and vice versa). The tool has two main
features: it allows
any arrangement of video quality depending on the layout, and it
extracts the
\ac{FoV} video from any point in the sphere.
\item We provide a comprehensive comparison of the different geometric arrangements of
video quality on 360-degree video. We address the main questions raised
by~\citet{facebook}: which layout provides the best trade-off
between bit-rate and
quality, how many video versions should be offered by the server, and what geometric
quality arrangement
enables the smoothest navigation.
\end{itemize}

In this short paper, we restrict our study to essentials, and we provide only our main findings based on a
sample of the results. \textit{Here are our findings...}




%%% Local Variables:
%%% mode: latex
%%% TeX-master: "paper"
%%% End:
