\section{Background and Related Work}
\label{sec:related}

We introduce the necessary geometric concepts for \GS{spherical}{}
videos, and discuss prospective architecture
proposals for navigable 360-degree video delivery.

\subsection{Geometric Layouts for 360-degree Videos}

A 360-degree video is captured in every direction from a unique point,
so it is essentially a \emph{spherical} video. Since video encoders
operate on a two-dimensional rectangular image, a key step of the
encoding chain is to project the spherical video onto a planar
surface. The projection of a sphere onto a plane (known as mapping)
has been studied for centuries. In this paper, we consider the four
projections that are the most discussed for 360-degree video
encoding~\cite{yu_framework_2015}. These layouts are depicted in
Figure~\ref{fig:mapping}.
%The advantages and shortcomings of every projection have been
%studied in the literature.
From the images that are projected on an \textit{equirectangular}
panorama, a \textit{cube map}, and a \textit{rhombic dodecahedron}, it
is possible to generate a viewport for any position and angle in the
sphere without any information loss~\cite{Ng2005, fu_rhombic_2009}.
However, some pixels are over-sampled (a pixel on the sphere is
projected to a pair of pixels in the projected image). This is
typically the case for the sphere pole when projected on the
equirectangular panorama. This over-sampling degrades the performance
of traditional video encoders~\cite{wojciechowski_h.264_2006,
yu_framework_2015}. On the contrary, the projection into a pyramid
layout causes under-sampling: some pairs of pixels on the sphere
%(i.e., those that are in the back of the view face)
are merged into a
single pixel in the projected image by interpolating their color
values. This under-sampling cause distortion and information loss in
the extracted FoV. Previous work regarding projection of spherical
videos into different geometric layouts focuses on enabling efficient
implementation of signal processing
functions~\cite{kazhdan_metric-aware_2010} and improving the video
encoding~\cite{tosic_low_2009}.
%Hence, the back
%view is the least probable head orientation of the video viewer, therefore the impact on the
%user experience is minimal.

\tikzsetnextfilename{2d_layout_projections}
\begin{figure}[t]
\centering
\begin{tikzpicture}
\def\sizeSphere{20}%pt
\def\ecartY{-1.2}%cm
\def\ecartX{6}

% da sphere
\pic [local bounding box=spher]  at (0,0) {spherical=15};

% recantagular
\pic [local bounding box=equi] at (-3,\ecartY) {equirectangular={\sizeSphere}{-1}{0}};

% cupe map
\pic [local bounding box=cubemap] at (-1,\ecartY) {cubemap=\sizeSphere};

% pyramid
\pic [local bounding box=pyra] at (1,\ecartY) {pyramid=\sizeSphere};

% rhombic
%\pgfdeclareimage[width=36 pt]{dodecahedron}{RhombicDodecahedron.png}
%\node at (3,\ecartY) (dodec)
%    {\pgfbox[center,center]{\pgfuseimage{dodecahedron}}};

\def\unitused{0.22}

\pic [local bounding box=dodeca] at (3,0.88*\ecartY) {dodecahedron=\unitused};

% links
\draw[-latex] (spher.180) -| (equi);
\draw[-latex] (spher.200) -| (cubemap);
\draw[-latex] (spher.340) -| (pyra);
\draw[-latex] (spher) -| (dodeca);

\node[font=\scriptsize,anchor=north] at (equi.south) {equirectangular};
\node[font=\scriptsize,anchor=north] at (cubemap.south) {cube map};
\node[font=\scriptsize,anchor=north] at (pyra.south) {pyramid};
\node[font=\scriptsize,anchor=north] at (dodeca.south) {\vphantom{y}dodecahedron};

\end{tikzpicture}
\caption{Projections into four geometric layouts}\label{fig:mapping}
\end{figure}

\parag{Our contributions}We propose to leverage the geometric
structure of the layouts to implement a video encoding based on
\ac{QEC}. Each geometric layout is characterized by a number of
\emph{faces} (\textit{e.g.}, 6 for the cube map, 12 for the
dodecahedron) and a given \emph{central point} (which corresponds to a
position on the sphere).
%(\textit{e.g.} the earth
% maps are usually centered so that the equator is in the middle of the
% map, but the longitude of the central $x$ point is not the same
% whether the map targets European, Asian or American people).
From a given central point and a given layout, our idea is to encode
the front face in full quality while the quality of other faces is
reduced.
%adjusted to the user's head movements and the viewing
%probability (e.g., the back face can be assigned low quality).
To our knowledge, such idea has not been studied yet.
Another originality of our work is that we measure \ac{QoE} by
measuring the quality of several extracted \GS{viewports}{} instead of
the full video.

\subsection{Personalized FoV-Only Streaming}

An intuitive idea to address the problem of resource waste due to the
delivery of non-\GS{displayed video data}{} is to stream only the part of the video that
corresponds to the \GS{viewport}. This solution however does not enable
fast navigation within the 360-degree video: when the client moves the
head, the FoV center changes, requiring a new viewport to be
immediately displayed. Since the device has no knowledge about other
parts of the spherical video, it has to notify the server about the
head movement and wait for the reception of the newly adjusted \GS{viewport}.
As seen in other interactive multimedia
systems~\cite{ChoyWSR14}, this solution cannot meet the \SI{10}{ms} latency
requirement in the standard Internet, even with the assistance of
\ac{CDN}. In addition, this solution requires the server to extract a
part of the video (thus to spend computing resources) for each client
connection.

\parag{Our contributions}In our system, the server always delivers
the full video, but it has different versions of this video depending
on the quality emphasized region (characterized by the QEC). The client device
selects the right representation and extracts the viewport. The
storage requirements at the server side increase but all the
processing is done at the client side (representation selection and
viewport extraction). This idea matches the adaptive delivery
solutions that content providers have \GS{recently}{} adopted % in recent years
(\textit{e.g.}~\ac{DASH}), trading client-personalized delivery for
simple server-side management operation.

\subsection{Tiling for Adaptive Video Streaming}
\GS{To deal with the cases of end-users consuming only a fraction of the
video (navigable
panorama~\cite{sanchez_compressed_2015,wang_mixing_2014,gaddam_tiling_2015}
and large-resolution video~\cite{jean16mmsys}), the most studied delivery solution
leverages the concept
of \emph{tiling}}.
%A delivery solution when the end-users consumes only a fraction of the
%video is based on the concept of \emph{tiling}. This proposal has been
%implemented for navigable panorama
%video~\cite{sanchez_compressed_2015,wang_mixing_2014,gaddam_tiling_2015}
%and large-resolution video~\cite{jean16mmsys}.
The idea is to
spatially cut a video into independent tiles. The server offers
multiple video representations of each tile; the client periodically
selects a representation for each tile and it has to reconstruct the
full video from these tiles before the viewport extraction.
% is carried out.
In a short paper,~\citet{ochi_live_2015} have sketched a
tile-based streaming system for 360-degree videos. In their proposal,
the spherical video is mapped onto an \emph{equirectangular} video,
which is cut into $8\!\times\! 8$ \emph{tiles}.

A tile-based adaptive streaming system provides the same features as
our proposed system regarding navigability (the clients get the full
video), bandwidth waste reduction (the video at low quality for
non-\ac{FoV} part) and \ac{QoE} maintenance (the downloaded video is
at full quality near the \ac{FoV} center). It has however several
critical weaknesses. First, the client has to first reconstruct the
video from independent tiles before the viewport extraction can take
place, which requires energy and time spent for each video frame.
Second, the more tiles there are, the less efficient the video
encoding is due to the tile
independence~\cite{sanchez_compressed_2015}. Third, the management at
the server is heavier because the number of files is larger. For
example, a typical $8\times8$ tiling offered at six quality levels
contributes to having 384~independent files for each video segment,
and this results in larger \ac{MPD} files (\GS{or}{} manifest
files). Finally, the management at the client side is heavier, as
well. For each tile, the client should run a representation selection
process and manage a specific network connection with the server.

\parag{Our contributions}In our system, the server
\GS{prepares $n$ QEC-based videos, each of them being a
pre-processed set of tile representations. Each QEC-based video is then
encoded at $k$ \emph{global} quality levels}.
%prepares
%(once and for all) \emph{one} video version per \ac{QEC}, each version
%being then encoded at several global quality levels. Each version is a
%pre-processed set of tile representations.
The main advantages include
an easier management for the server (fewer files hence a smaller
\ac{MPD} file), a simpler selection process for the client (by a
distance computation), and no need for re-constructing the video before
the viewport extraction.
% \noteXC{that's not true since last week
%modification in our system. Now that we have an independent track per
%video it is needed to re-construct the $2$D layout, but having
%everything in the same video container is much easier for the download
%and the time synchronization.}.

\subsection{QEC-Based Streaming}

A  provider of 360-degree videos (Facebook) has recently
released details about the implementation of its delivery
platform~\cite{facebook}.
% Their system is based on the same idea as
%our concept of \ac{QEC}.
\GS{The spherical video is projected onto a pyramid layout from multiple
(up to 30) central points to generate a set of video representations.
Since the
front face of pyramid projection has a better image quality than the other faces, the
system is in essence similar as our concept of \ac{QEC}. The end-users
periodically select one of the representations
based on their \ac{FoV} center}. This implementation
corroborates that, from an industrial perspective, the extra-cost of
generating and storing multiple \ac{QEC}-based representations of the
same video is compensated by bandwidth savings and
enhanced system usability.
%This system uses projections of the
%spherical videos into two layouts: a pyramid and a cube map.
\GS{However, as we will see in Section~\ref{sec:settings}, the pyramid projection is not
the best regarding the viewport quality. Moreover, the system
uses the same video quality on each face, which is less
efficient than our proposal. Finally, the impact of the video encoding on the solution
is not given}.

\parag{Our contributions}Our approach is based on the same
idea of offering multiple \ac{QEC}-based video representations.
However, we provide a complete study of our system with the additional
distinction of having varying quality across the geometrical layout. Moreover,
our study includes an evaluation of several
geometric layouts, an analysis of the best segment duration, \XC{an
analysis of the best number of \acp{QEC},}{}
and a step towards integration into MPEG \ac{DASH}.
%associated with a given representation, based on the specific
%\ac{QEC}
